<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Sk MIraj Ahmed</title>
  
  <meta name="author" content="Sk Miraj Ahmed">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style type="text/css">
  /* Design Credits: Jon Barron and Dripta S. Raychaudhuri*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  papertitle {
  font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
  font-size: 18px;
  font-weight: 700
}

  </style>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!--   <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p align="center"><font size="7">Sk Miraj Ahmed</font>
              <p>
                I am currently working as a Computational Science Research Associate at the <a href="https://www.bnl.gov/compsci/">Computational Science Initiative (CSI)</a>, Brookhaven National Laboratory. My research focuses on developing novel computer vision and machine learning algorithms, with a special emphasis on accelerating fundamental scientific discoveries. Prior to joining the lab, I completed my PhD at the <a href="https://www.ucr.edu/">University of California, Riverside</a>, under the supervision of <a href="https://vcg.ece.ucr.edu/amit">Dr. Amit K. Roy-Chowdhury</a>, where I worked on <strong>Source-Free Unsupervised Domain Adaptation</strong> and its diverse applications in computer vision. My research experience extends to areas such as <strong>multimodal learning</strong>, <strong>test-time adaptation</strong>, and <strong>privacy in machine learning</strong>. During my PhD, I had the opportunity to intern at <a href="https://www.merl.com/"> Mitsubishi Electric Research Laboratories </a>. I hold a master’s degree in electrical engineering from the <a href="https://ee.iisc.ac.in/">Indian Institute of Science, Bangalore</a>, where I focused on <strong>3D reconstruction</strong> using novel <strong>convex optimization</strong> techniques, and a bachelor’s degree in electrical engineering from <a href="https://jadavpuruniversity.in/academics/electrical-engineering/">Jadavpur University, Kolkata</a>.
                <!-- I am a PhD candidate at the <a href="https://vcg.ece.ucr.edu/">Video Computing Group</a> of the <a href="https://www.ucr.edu/">University of California, Riverside</a> under the guidance of  <a href="https://vcg.ece.ucr.edu/amit">Dr. Amit K. Roy-Chowdhury</a>. My current research revolves around <strong>Source-Free Unsupervised Domain Adaptation</strong> and its diverse applications in computer vision. Additionally, my research experience extends to various areas, including <strong>Multimodal learning</strong> and <strong>Test-Time Adaptation</strong>. At present, I am actively exploring the area of <strong>Privacy in Machine Learning</strong> models as part of my ongoing research. During PhD, I was very fortunate to have interned at <a href="https://www.merl.com/"> Mitsubishi Electric Research Laboratories </a>. -->
              </p>              
              <p style="text-align:center">
                <a href="mailto:sahme047@ucr.edu">Email</a> &nbsp/&nbsp
                <a href="data/CV_miraj_updated-3.pdf">CV</a> &nbsp/&nbsp              
                <a href="https://scholar.google.com/citations?user=GcOJlW8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/miraj-ahmed-94727167/">LinkedIn</a> 
                <!-- <a href="https://github.com/driptaRC">GitHub</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Website_pic_1.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Website_pic_1.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <sectionheading>Updates</sectionheading>
              <p>
              <!-- &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> July 2023: Joined <a href="https://www.amazon.science/">AWS AI</a> as an applied scientist!  -->
              <!-- <br></br>    -->
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> February 2025: Two papers accepted at CVPR 2025! 
              <br></br> 
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> September 2024: One paper accepted at <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/ec4c05921d70202023898568a2a8c002-Paper-Conference.pdf">NeurIPS 2024</a>! 
              <br></br>  
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> July 2024: Joined Brookhaven National Laboratory as a research associate! 
              <br></br>  
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> October 2023: One paper accepted at <a href="https://arxiv.org/pdf/2311.04991.pdf">WACV 2024</a>! 
              <br></br>  
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> July 2023: One paper accepted at <a href="https://iccv2023.thecvf.com/">ICCV 2023</a>! 
              <br></br>   
              <!-- &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> June 2022: Book chapter published in <a href="https://www.sciencedirect.com/handbook/handbook-of-statistics/volumes">'Handbook of Statistics, Vol. 48'</a>!  -->
              <!-- <br></br>    -->
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> July 2022: One paper accepted at <a href="https://eccv2022.ecva.net/">ECCV 2022 (Oral)</a>! 
              <br></br>
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> June 2021: Joined <a href="https://www.merl.com/">MERL</a> as a summer intern!
              <br></br>
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> February 2021: One paper accepted at <a href="https://cvpr2021.thecvf.com/">CVPR 2021 (Oral)</a>!

              <br></br>
              &nbsp<i class="fa fa-share-alt" style="font-size:12px"></i> February 2020: One paper accepted at <a href="https://cvpr2020.thecvf.com/">CVPR 2020 </a>!

            
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <sectionheading>Accepted Publications</sectionheading>
              <p>
                <!-- My research is centered around developing algorithms to make machine learning models adaptable to a variety of distributional shifts, encompassing scenarios such as camera viewpoint changes, morphological changes of embodied agents and dynamic computational resource variations, with as minimal supervision as possible. -->
            </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2311.04991.pdf">
                <papertitle>Effective Restoration of Source Knowledge in Continual Test Time Adaptation</papertitle>
              </a>
              <br>
              Fahim Faisal Niloy, <strong>Sk Miraj Ahmed</strong> , Dripta S. Raychaudhuri, Samet Oymak and Amit K. Roy-Chowdhury
              <br>
              <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2024
              <br>
            </td>
          </tr> 
          
       <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2308.11880.pdf">
                <papertitle>SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets</papertitle>
              </a>
              <br>
              Cody Simons, Dripta S. Raychaudhuri,<strong>Sk Miraj Ahmed</strong> , Suya You, Konstantinos Karydis and Amit K. Roy-Chowdhury
              <br>
              <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023 
              <br>
            </td>
          </tr> 
          
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://books.google.com/books?hl=en&lr=&id=4sCqEAAAQBAJ&oi=fnd&pg=PA81&dq=info:vylSLN7IAfsJ:scholar.google.com&ots=Ma5DASt5bB&sig=o9sWDanO6WqrkNPzMviVAEm-o_M#v=onepage&q&f=false">
                <papertitle>Source distribution weighted multisource domain adaptation without access to source data</papertitle>
              </a>
              <br>
              <strong>Sk Miraj Ahmed</strong>, Dripta S. Raychaudhuri, Samet Oymak and Amit K. Roy-Chowdhury
            
              <br>
              <em>Deep Learning 48, 81</em>, 2023 
              <br>
            </td>
          </tr>   
          
          
       <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2209.04027.pdf">
                <papertitle>Cross-Modal Knowledge Transfer Without Task-Relevant Source Data</papertitle>
              </a>
              <br>
              <strong>Sk Miraj Ahmed</strong>, Suhas Lohit, Kuan-Chuan Peng, Michael J. Jones and Amit K. Roy-Chowdhury
              <br>
              (* equal contribution)
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022 (Oral) 
              <br>
            </td>
          </tr>   
          
          
       <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2104.01845">
                <papertitle>Unsupervised Multi-source Domain Adaptation Without Access to Source Data</papertitle>
              </a>
              <br>
              <strong>Sk Miraj Ahmed*</strong>, Dripta S. Raychaudhuri*, Sujoy Paul*, Samet Oymak and Amit K. Roy-Chowdhury
              <br>
              * equal contribution
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021 (Oral) 
              <br>
            </td>
          </tr>   
          
       <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2007.11149.pdf">
                <papertitle>Camera on-boarding for person re-identification using hypothesis transfer learning</papertitle>
              </a>
              <br>
              <strong>Sk Miraj Ahmed</strong>, Aske R. Lejbolle, Rameswar Panda and Amit K. Roy-Chowdhury
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020
              <br>
            </td>
          </tr>   
          
        <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1904.04218.pdf">
                <papertitle>Least-squares registration of point sets over SE (d) using closed-form projections</papertitle>
              </a>
              <br>
              <strong>Sk. Miraj Ahmed</strong> Niladri R. Das and Kunal N. Chaudhury
              <br>
              <em>Computer Vision and Image Understanding (CVIU)</em>, 2019
              <br>
            </td>
          </tr>
          
        
          
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8296429">
                <papertitle>Global multiview registration using non-convex ADMM</papertitle>
              </a>
              <br>
              <strong>Sk Miraj Ahmed</strong>, and Kunal N. Chaudhury
              <br>
              <em>International Conference on Image Processing (ICIP)</em>, 2017
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8004486">
                <papertitle>A scalable ADMM algorithm for rigid registration</papertitle>
              </a>
              <br>
              Rajat Sanyal, <strong>Sk Miraj Ahmed</strong>, M jaiswal and Kunal N. Chaudhury
              <br>
              <em>IEEE Signal Processing Letters (SPL)</em>, 2017
              <br>
            </td>
          </tr>
        </tbody></table>
  
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr><td><br><p align="right"><font size="2">
    Template taken from <a href="http://www.cs.berkeley.edu/~barron/">here</a>
    </font></p></td></tr>
</tbody></table>
</body>

</html>
